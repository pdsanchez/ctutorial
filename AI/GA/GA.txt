Holland, J.H. (1975) desarrolló el concepto de algoritmo genético.
Los algoritmos genéticos son procesos estocásticos (no determinista, aleatorio) dictados por estadística.
Aunque no suelen ser la mejor elección para resolver un problema muy específico (suele haber mejores soluciones para un problema concreto), son una excelente herramienta genérica que se puede aplicar a diferentes problemas. Son la navaja suiza del aprendizaje automático:
- Problemas difíciles de implementar o de resolver.
- Problemas que cambian constantemente y que requieren una solución adaptativa.
- Problemas en los que no se puede encontrar todas las posibles soluciones y una solución buena (no la mejor) es aceptable.
- Problemas basados en restricciones (constraint satisfaction problems). Problemas con una serie de variables que se establecen y que deben cumplirse. Las restricciones pueden ser "hard constraints" (tienen que satisfacerse para llegar a la solución) o "soft constraints" (es preferible que se cumplan para llegar a una mejor solución)

Términos:
- Population – colección de candidatos (soluciones) sobre los que se aplican operadores genéticos (crossover y mutación)
- Candidate Solution – una posible solución a un problema dado.
- Gene – bloque indivisible que conforma el cromosoma.
- Chromosome – cadena de genes que define un candidato (solución) específico. Un cromosoma codifica una solución.
- Mutation – proceso que modifica un gen aleatoriamente.
- Crossover (recombination) – proceso de combinación de genes para crear un nuevo candidato (offspring)
- Selection – tomar un candidato para generar la siguiente generación de soluciones.
- Fitness – puntuación que mide el grado en el que un candidato se ajusta a la solución del problema dado. Lo contrario al fitness se denomina "cost".
- Allele – valores que puede tomar un rasgo específico.
- Locus – posición del cromosoma que codifica un rasgo.
- Gene Pool – toda la información genética posible de la población.
- Survival of the fittest – sólo los individuos más aptos sobreviven y pasan su DNA (selective pressure). La presión selectiva guía lentamente la evolución para encontrar los individuos mejor adaptados.
- Search Spaces - En los problemas de optimización con numerosas soluciones, la colección de soluciones es el espacio de búsqueda.
Cada punto específico del espacio de búsqueda es una solución candidata del problema. 
Las soluciones que están próximas son más propensas a tener rasgos similares que las que están lejos.
La distancia entre las soluciones en el espacio de búsqueda se puede aprovechar para afinar la búsqueda.
- Fitness Landscapes - Cada solución candidata tiene asociada un fitness lo que genera una gráfica de simas y colinas.
Los algoritmos de optimización deben evitar los óptimos locales y buscar soluciones próximas al óptimo global:
Simulated Annealing y Tabu search son variaciones del hill climbing algorithm que evitan los óptimos locales.
Los algoritmos genéticos son buenos evitando los óptimos locales porque su población se distribuye a lo largo de todo el espacio de búsqueda y localiza los óptimos para continuar la búsqueda en esas zonas. Esto se debe a que las peores soluciones se eliminan y la recombinación genera mejores soluciones. La mutación permite saltar de la posición actual a otras posiciones del espacio de búsqueda.

Parametros:
- Mutation Rate: probabilidad de que un gen específico de un cromosoma mute. 
Una tasa de mutación alta provoca mayor diversidad genética en la población y facilita evadir óptimos locales, pero también se pierden candidatos buenos.
Una tasa de mutación baja aumenta el tiempo de localización de la mejor solución.
- Population Size: número de individuos del algoritmo genético. A mayor número, mayor es el espacio de búsqueda que se abarca (y por tanto mejores soluciones), y mayores los recursos computacionales demandados.
- Crossover Rate: frecuencia con la que se aplica la recombinación. Una tasa de recombinación alta dará lugar a un mayor número de soluciones encontradas.
- Elitism: permite pasar los mejores individuos sin alterar (no se les aplica recombinación ni mutación) a la siguiente generación.
Suele tomar un valor muy bajo en relación a la población total.
Si el valor es muy alto, el tiempo de búsqueda del algoritmo aumenta.


Encoding
Initialization
Evaluation
Elitism
Crossover - Selection Method
Mutation
Execution
Termination Check
Validation


# Encoding (representación genética)
Modo de codificar la información genética en el cromosoma (binaria, enteros, decimales, objetos, tree-based...)
- binario (0s y 1s)
- permutation encoding (secuencias de genes conocidas - genes identificados por un id)



# Termination Check (condiciones de terminación)
• Se alcanza un número máximo de generaciones.
• Se excede un tiempo máximo.
• Se encuentra una solución que satisface los requerimientos establecidos.
• El algoritmo se estabiliza.

# Validation:
Los algoritmos genéticos son procesos estocásticos (no determinista, aleatorio) dictados por estadística. No se puede sacar ninguna conclusión con una única prueba. El inicializar el proceso con una población inicial aleatoria da lugar a soluciones óptimas diferentes, lo que hace dificil juzgar el comportamiento.



Proceso de búsqueda:
1. Inicializar población de soluciones candidatas (normalmente al azar para cubrir todo el espacio de búsqueda)
2. Evaluación: Asignar fitness a cada individuo y determinar el fitness promedio de la población.
3. Determinar en función de las condiciones de terminación si se finaliza o se continúa.
4. Si no se cumple la condición de terminación se seleccionan individuos por su fitness (a mayor fitness, mayor probabilidad de seleccionarlo)
5. Apricar recombinación y mutación a los individuos seleccionados. Se crean nuevos individuos para la siguiente generación.
6. Evaluación y comenzar el proceso de nuevo (cada ciclo del loop se denomina generación)
7. Cuando se cumple la condición de terminación se retornan los resultados de la búsqueda.



1:generation = 0;
2:population[generation] = initializePopulation(populationSize);
3:evaluatePopulation(population[generation]);
4:While isTerminationConditionMet() == false do
5:  parents = selectParents(population[generation]);
6:  population[generation+1] = crossover(parents);
7:  population[generation+1] = mutate(population[generation+1]);
8:  evaluatePopulation(population[generation]);
9:  generation++;
10:End loop;



The ‘main’ method represents the pseudocode.

• A GeneticAlgorithm class, which abstracts the genetic algorithm itself and provides problem-specific implementations of interface methods, such as
crossover, mutation, fitness evaluation, and termination condition checking.
rewrite: calcFitness, evalPopulation, isTerminationConditionMet, selectParent, crossoverPopulation, mutatePopulation, initPopulation, calcPopu­lation
• An Individual class, which represents a single candidate solution and its chromosome.
delete the constructor with the signature “public Individual(int chromosomeLength)” -- randomly initializes the chromosome
• A Population class, which represents a population or a generation of Individuals, and applies group-level operations to them.

La función de fitness suele ser la que más recursos demanda

calcFitness(Individual individual) method to the GeneticAlgorithm

We also need a simple helper method to loop over every individual in the
population and evaluate them (i.e., call calcFitness on each individual). Let’s call this
method evalPopulation(Population population)

public GeneticAlgorithm(int populationSize, double mutationRate, double crossoverRate, int elitismCount) { }
public Population initPopulation(int chromosomeLength) { }
public double calcFitness(Individual individual) { }
public void evalPopulation(Population population) { }
public boolean isTerminationConditionMet(Population population) { }
public Individual selectParent(Population population) { }
public Population crossoverPopulation(Population population) { }
public Population mutatePopulation(Population population) { }


We have four more methods to implement in the GeneticAlgorithm class: isTerminationConditionMet, selectParent, crossoverPopulation, and mutate Population.




public static void main(String[] args) {
  // Create GA object
  GeneticAlgorithm ga = new GeneticAlgorithm(100, 0.001, 0.95, 2);
  // Initialize population
  Population population = ga.initPopulation(50);
  // Evaluate population
  ga.evalPopulation(population);*
  // Keep track of current generation
  int generation = 1;
  while (ga.isTerminationConditionMet(population, maxGenerations) == false) {
    // Print fittest individual from population
    System.out.println("Best solution: " + population.getFittest(0).toString());
    // Apply crossover
    population = ga.crossoverPopulation(population);
    // Apply mutation
    population = ga.mutatePopulation(population);
    // Evaluate population
    ga.evalPopulation(population);*
    // Increment the current generation
    generation++;
  }
  System.out.println("Found solution in " + generation + "generations");
  System.out.println("Best solution: " + population.getFittest(0).toString());
}



Durante la recombinación, cada individuo de la población se considera para recombinarse (para esto se usa la tasa de recombinación)
Se compara la tasa de recombinación con un número aleatorio para decidir si sobre el individuo se aplica recombinación o no.
Si un individuo se selecciona para recombinarse, entonces hay que buscar un segundo padre a través de un método de selección:
- Roulette Wheel Selection (fitness proportionate selection): los individuos se sitúan en una ruleta, y a mayor fitness, mayor espacio ocupan en la misma.
- Tournament Selection: selección de individuos en función del fitness (a mayor fitness, mayor probabilidad de ser elegido para la recombinación)
Los padres se seleccionan al ejecutarse una serie de torneos. En primer lugar un determinado número de individuos (tournament size) son elegidos aleatoriamente de la población. Después esos individuos compiten unos contra otros comparando sus fitness. El individuo con mayor fitness es elegido como padre.
Un tournament size alto puede provocar una pérdida de la diversidad genética (sólo los mejores individuos son seleccionados como padres). Un valor bajo puede enlentecer el progreso del algoritmo al reducir la presión selectiva.
Para que se puedan tomar individuos con un bajo fitness se añade una probabilidad de selección. Si esa probabilidad es del 0.6, existe un 60% de probabilidades de seleccionar al individuo con mayor fitness. Si ese individuo no se selecciona se pasa al siguiente con mayor fitness, y así sucesivamente hasta que se selecciona uno.
Esto permite que incluso los individuos con peor fitness sean seleccionados en algunas ocasiones. 
También podría tenerse en cuenta la diferencia de fitness entre los individuos (si es muy alta o muy baja) 
- Stochastic Universal Sampling (forma avanzada del fitness proportional selection)


Crossover Methods (intercambio de información)
- Uniform crossover: cada gen del offspring tiene un 50% de probabilidad de venir de un padre u otro
- Single point crossover: se selecciona aleatoriamente una posición del genoma, la información genética anterior a ese punto procederá del padre 1 y la posterior del padre 2. Existen algunas combinaciones que no son posibles (aunque se pueden dar por mutación) y existe bias en la izquierda derivada del padre 1 y a la derecha procedente del padre 2 (para evitarlo se usa el two-point crossover)
- Two-point crossover
- Ordered crossover: un subconjunto del primer padre es seleccionado y añadido al cromosoma hijo en la misma posición. Para añadir la información del segundo padre empezamos en la posición final del subconjunto seleccionado e incluimos cada gen del padre 2 (siempre que no estén ya en el hijo - offspring)

Crossover Pseudo Code
1:For each individual in population:
2:  newPopulation = new array;
3:  If crossoverRate > random():
4:    secondParent = selectParent();
5:    offspring = crossover(individual, secondParent);
6:    newPopulation.push(offspring);
7:  Else:
8:    newPopulation.push(individual);
9:  End if
10:End loop;


Mutación
Permite situar aleatoriamente candidatos en nuevos puntos del espacio de soluciones. Mejora los resultados a largo plazo.
- Bit Flip mutation
- Swap mutation: se seleccionan dos genes y se cambian sus posiciones. 
Se considera cada gen del cromosoma de un individuo y si es seleccionado (en función de su tasa de mutación), se selecciona otro gen aleatoriamente y se intercambian. 
























OPTIMIZATION

Adaptive Genetic Algorithms (AGA)
Ayudan a tunear automáticamente los parámetros en función del estado del algoritmo.
Este ajuste se realiza mientras el algoritmo genético se ejecuta. Para ello usa información como el fitness medio de la población y el mejor fitness individual de la población.
Podemos determinar si el algoritmo comienza a converger calculando la diferencia entre el mejor fitness actual y el fitness medio de la población. 
Cuando el fitness medio de la población es próximo al mejor fitness actual, la población ha comenzado a converger en torno a un equeño área del espacio de búsqueda.


Multi-Heuristics
Implementar una segunda heurística en el algoritmo genético da mayor control a la estrategia de búsqueda y ejecución.
Dos heurísticas que se suelen usar con los algoritmos genéticos son:
- Simulated annealing: es un algoritmo de hill climbing que gradualmente reduce el ratio en el que peores soluciones son aceptadas. En los algoritmos genéticos se usa para reducir el ratio de mutación y recombinación a lo largo del tiempo (permite controlar la velocidad de convergencia del algoritmo genético)
- Tabu search: algoritmo de búsqueda que evita que el algoritmo busque de nuevo en zonas ya visitadas. Esto evita considerar de nuevo las soluciones que se consideran malas.


Performance Improvements (lo más efectivo es escribir código eficiente)
-Fitness Function Design
La función de fitness es la que más proceso demanda. 
A través de esta función el algoritmo genético focaliza la búsqueda en las mejores áreas del espacio de búsqueda.
-Parallel Processing
Modern computers will often come equipped with several separate processing
La función de fitness suele ser el cuello de botella, por lo que se suele procesar en paralelo (se calcula el fitness de numerosos individuos simultaneamente)
En Java 8 se puede usar IntStream para no tener que preocuparse de los detalles del procesado en paralelo (se crea automáticamente el número de hilos óptimo en función de los cores disponibles)
Al usar hilos hay que evitar que los objetos de un hilo afecten a los objetos de otro hilo (no hay que usar el mismo objeto al mismo tiempo, para evitarlo hay que clonar el objeto)
-Fitness Value Hashing
Usar una caché puede reducir el tiempo de cálculo de valores computados previamente (en sistemas distribuidos se puede usar un servicio de cache centralizado - Redis o memcached)
Durante la ejecución pueden surgir soluciones previamente evaluadas, con lo que la caché evitará calcular de nuevo el fitness.
-Encoding
En teoría cualquier problema puede ser representado usando codificación binaria, pero no suele ser lo más eficiente.
-Mutation and Crossover Methods
Elegir buenos métodos de recombinación y mutación es importante para mejorar la ejecución del algoritmo genético.
Hay que tener en cuenta factores como el grado de mutación. Si un método de mutación redondea el valor a 0 o 10, no es lo mismo un cambio pequeño (de 1 a 0 por ejemplo) que uno grande (de 5 a 10 por ejemplo). Además se genera un sesgo al existir preferencia por los valores 0 y 10.



















































































traveling salesman problem (TSP)
--------------------------------
optimization problem - involves finding the most efficient route through a collection of cities, visiting each city exactly once.
The only guaranteed method to produce an optimal solution for the traveling
salesman problem is by using a brute force algorithm. A brute force algorithm is an
algorithm designed to systematically try every possible solution.
Attempting solving
the traveling salesman problem with a brute force algorithm is an extremely hard
task because the number of potential solutions experiences factorial growth as the
number of cities is increased. For example, for 5 cities, there are 120 possible solutions (1x2x3x4x5), and for 10
cities that number will have increased to 3,628,800 solutions! 
There are a
number of different algorithms that can quickly find solutions that are likely to
be within only a couple of percent of optimal. One of the more commonly used
algorithms is the nearest neighbor algorithm. With this algorithm, a starting city
is picked at random. Then, the next nearest unvisited city is found and picked as
the second city in the route. This process of picking the next nearest the unvisited
city is continued until all cities have been visited and a complete route has been
found. The nearest neighbor algorithm has been shown to be surprisingly effective
at producing reasonable solutions that score within a fraction the optimal solution.

We can calculate this distance with the “Euclidean distance”. This usually isn’t going to be a typical case as there could be various obstacles making the actual shortest path much longer than the Euclidean
distance. We are also assuming that traveling from City-A to City-B takes just as
long as traveling from City-B to City-A. Again, in reality this is rarely the case. Often
there will be obstacles such as one-way roads that will affect the distance between
cities while traveling in a certain direction. An implementation of the traveling
salesman problem where the distance between the cities changes depending on
the direction is called an asymmetric traveling salesman problem.

Encoding - a list of cities in order. We can do this by assigning each city a unique ID then referencing
it using a chromosome in the order of the candidate route (permutation encoding)
The chromosome must be of a certain length
(however long the city tour is), but an additional constraint is that each city must
be visited once and only once, otherwise the chromosome is invalid. There can be
no duplicate genes in the chromosome, and there can be no omitted cities in the
chromosome.

Evaluation
calculate the total distance of the
route given by the individual’s chromosome.
the fitness is calculated by dividing 1 by the total route distance –
a shorter distance therefore has a higher score.

As usual, this function loops over the population and each individual’s fitness
is calculated. Unlike previous implementations, we’re calculating an average
population fitness instead of a total population fitness. (Since we’re using
tournament selection rather than roulette wheel selection, we don’t actually need
the population’s fitness; nothing would change if we simply didn’t record this value.)

Termination Check
As we have already learned, there is no way to know if we have found an optimal
solution to the traveling salesman problem unless we try every possible solution.
This means the termination check we use in this implementation cannot termi-
nate when the optimal solution has been found, because it simply has no way of
knowing.
Note, however, that in situations like these—where the best solution can not
be known—that there are many sophisticated techniques for termination beyond
simply setting an upper bound on the number of generations.
One common technique is to measure the improvement of the population’s
fitness over time. If the population is still improving rapidly, you may want to allow
the algorithm to continue on. Once the population stops improving, you can end
the evolution and present the best solution.
You may never find the globally optimum solution in a complex solution space
like the traveling salesman problem’s, but there are many strong local optima, and a
plateau in progress typically indicates that you’ve found one of these local optima.
There are several ways you can measure the progress of a genetic algorithm over
time. The simplest method is to measure the number of consecutive generations
where there has been no improvement in the best individual. If the number of
generations with no improvement has crossed some threshold, for instance 500
generations with no improvement, you can stop the algorithm.
One drawback of this simple approach with large solution spaces is that you may
see constant improvement in the population’s fitness – it just may be painfully slow!
There are so many combinations that it’s feasible to get a one-point improvement
every dozen generations or so, and you’ll never actually encounter 500 consecutive
generations with no improvement. You could, of course, set a maximum upper
bound on generations irrespective of improvement. You could also implement
a more sophisticated technique, such as taking the moving average of various
windows and comparing them against each other. If the fitness improvement has
been trending downwards for several windows, stop the algorithm.

Crossover
With the traveling salesman problem, both the genes and the order of the genes
in the chromosome are very important. In fact, for the traveling salesman problem
we shouldn’t ever have more than one copy of a specific gene in our chromosome.
the order of the chromosome affects
the solution’s fitness. In fact, it’s only the order that matters.
the uniform crossover
method works on the level of individual genes and doesn’t respect the order of
the chromosome. Single-point and two-point crossover methods do a better job
as they deal with chunks of the chromosome, which will preserve order within
those chunks. The problem with single-point and two-point crossover though, is
that they aren’t careful about which genes are being added and removed from
the chromosome. This means we are likely to end up with invalid solutions with
chromosomes that contain more than one reference for the same city or have cities
missing altogether.
A crossover method, which addresses both these problems, is ordered crossover.
In this crossover method, a subset of the first parent’s chromosome is selected. That
subset is then added to the child chromosome in the same position.
The next step is to add the second parent’s genetic information to the offspring’s
chromosome. We do this by starting from the end position of the selected subset,
and then include each gene from parent 2, which isn’t already in the offspring’s
chromosome.

P1 1 2 | 5 3 6 | 4
P2 5 1 | 4 3 6 | 2
Of     | 5 3 6 | 

In this example, we would start from the gene “2” checking if it can be found in the
offspring’s chromosome. Because 2 isn’t currently in the offspring’s chromosome,
we can add it to the first available position in the offspring’s chromosome. Then,
because we reached the end of parent 2’s chromosome, we go back to the first
gene, “5”. This time the 5 is in the offspring’s chromosome so we skip it and move
onto the 1. We keep doing this until we end up with the following:

P1 1 2 | 5 3 6 | 4
P2 5 1 | 4 3 6 | 2
Of 2 1 | 5 3 6 | 4

This method of crossover retains a lot of the order from the parents, but also
ensures solutions remain valid for problems such as the traveling salesman problem.
this technique requires checking the offspring’s chromosome for the existence
of a specific gene.






Schedule
---------
El horario de clases es una variación del constraint satisfaction problem. 
Estos problemas tienen un conjunto de variables que hay que asignar de modo que no se viole el conjunto de restricciones definido (hard constraints y soft constraints)
A veces las soft constraints generan conflictos entre sí. Se pueden dar pesos a esas restricciones para que el algoritmo sepa cuales son las más importantes.




